{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "wKYyFaqJwHjP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wKYyFaqJwHjP",
    "outputId": "141786e6-5c36-4630-c7c3-22d25f9d7ced"
   },
   "outputs": [],
   "source": [
    "# # initiate the graph\n",
    "# movie_hetero_graph = dgl.heterograph(graph_data) \n",
    "# movie_hetero_graph_clean = clean_graph(movie_hetero_graph, users_df, movie_df, ratings_df)\n",
    "\n",
    "# print(movie_hetero_graph)\n",
    "# print(\"-------------------\")\n",
    "# print(movie_hetero_graph_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "71824cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "graphs, _ = dgl.load_graphs(\"/Users/pratikaher/SPRING23/Capstone/GNN_Architecture/run_data/graph_files_subgraph/ecommerce_hetero_graph.dgl\")\n",
    "ecommerce_hetero_graph = graphs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e3b27924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes={'customer': 96516, 'product': 32171},\n",
       "      num_edges={('customer', 'orders', 'product'): 115609, ('product', 'rev-orders', 'customer'): 115609},\n",
       "      metagraph=[('customer', 'product', 'orders'), ('product', 'customer', 'rev-orders')])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecommerce_hetero_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iDwmnrd5lK4E",
   "metadata": {
    "id": "iDwmnrd5lK4E"
   },
   "source": [
    "# Structural Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9HbV4wyJJVra",
   "metadata": {
    "id": "9HbV4wyJJVra"
   },
   "source": [
    "### Deep Random Walk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dsirOQMzwf",
   "metadata": {
    "id": "b0dsirOQMzwf"
   },
   "source": [
    "**Network Embeddings**\n",
    "\n",
    "Network embedding, i.e., network representation learning (NRL), is proposed to **embed network into a low dimensional space while preserving the network structure and property** so that the learned embeddings can be applied to the downstream network tasks. \n",
    "\n",
    "* random walk\n",
    "* deep neural network\n",
    "* matrix factorization\n",
    "\n",
    "All these algorithms are proposed for the **homogeneous graphs**.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "**Deep Random Walk**\n",
    "\n",
    "Transfer graph into vectors. The representation vector carries structural information about nodes and its neighbor.\n",
    "\n",
    "Steps:\n",
    "1. Generate a random walk (a list of nodes walked) for each node\n",
    "2. To make it a feature (for each node), \n",
    "  - Use the classic walk (an 1D array)\n",
    "  - Make a revision of the walk, e.g. user_only_walk, movie_only_walk (a shorter 1D array)\n",
    "  - Calculate a score, e.g. cnt of different movies reached (a single value)\n",
    "  - Transform into embeddings\n",
    "\n",
    "TODO:\n",
    "1. Nodes in this graph should have unique ids, otherwise from the embeddings we can't distinguish nodes with same id but different node types.\n",
    "2. Check that the similarity of embedding reflects the real situation\n",
    "\n",
    "\n",
    "Backlog:\n",
    "1. Allow more walks per node (not implemented)\n",
    "\n",
    "\n",
    "Source:\n",
    "\n",
    "[DeepWalk: Online Learning of Social Representations](https://arxiv.org/pdf/1403.6652.pdf)\n",
    "\n",
    "[DeepWalk Implementation](https://towardsdatascience.com/exploring-graph-embeddings-deepwalk-and-node2vec-ee12c4c0d26d)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "85bvxZAlJ3VA",
   "metadata": {
    "id": "85bvxZAlJ3VA"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from typing import List\n",
    "import copy\n",
    "import torch\n",
    "from torch import nn\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "class DeepWalk:\n",
    "    def __init__(self, g: dgl.DGLGraph, node_edge_pairs: List, walk_length: int, walks_per_node: int):\n",
    "        \"\"\"\n",
    "        :param walk_length: length of the walk\n",
    "        :param walks_per_node: number of walks per node\n",
    "        \"\"\"\n",
    "        self.walk_length = walk_length\n",
    "        self.walk_per_node = walks_per_node # backlog\n",
    "        self.num_of_nodes = g.number_of_nodes()\n",
    "        self.num_of_nodes_ntype = []\n",
    "        for pair in node_edge_pairs:\n",
    "            ntype = pair[0]\n",
    "            self.num_of_nodes_ntype.append([ntype, len(g.nodes[ntype])])\n",
    "        self.walks = self._forward(g, node_edge_pairs)\n",
    "\n",
    "    def _forward(self, g: dgl.DGLGraph, node_edge_pairs: List) -> dict:\n",
    "        \"\"\"\n",
    "        Generate a random walk for every node in the graph. \n",
    "        :param g: Graph\n",
    "        :param node_edge_pairs: [node type, 1st level edge type, 2nd level edge type]\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        nodes_walk = {}\n",
    "        for pair in node_edge_pairs:\n",
    "            ntype = pair[0]\n",
    "            nodes_walk[ntype] = []\n",
    "            for start in g.nodes(ntype).tolist():\n",
    "                walk = [start]\n",
    "                for i in range(self.walk_length):\n",
    "                    current = walk[i]\n",
    "                    if i%2 == 0:\n",
    "                        neighbors = g.successors(current, etype=pair[1]).tolist()\n",
    "                    else:\n",
    "                        neighbors = g.successors(current, etype=pair[2]).tolist()\n",
    "                    next = random.choice(neighbors) # random sampling (equal probabilities)\n",
    "                    walk.append(next) # walk to the next node\n",
    "                nodes_walk[ntype].append(walk)\n",
    "        return nodes_walk\n",
    "\n",
    "    def get_feature_walk(self, node_type_restriction=False):\n",
    "        \"\"\"\n",
    "        Return the walks.\n",
    "        :param node_type_restriction: Default `False`. If `True`, return walks that contains only the type of the start node.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if not node_type_restriction:\n",
    "            return self.walks\n",
    "        else:\n",
    "            walks = copy.deepcopy(self.walks)\n",
    "            ntypes = walks.keys()\n",
    "            for ntype in ntypes:\n",
    "                for w in walks[ntype]:\n",
    "                    # Remove nodes with odd indices. In the walk list, even indices have the same node type as start node.\n",
    "                    del w[1::2]\n",
    "            return walks\n",
    "\n",
    "    def get_feature_diversity_score(self):\n",
    "        \"\"\"\n",
    "        Return a score of (cnts of different nodes in the walk)/(walk length).\n",
    "        \"\"\"\n",
    "        walks = self.get_feature_walk(node_type_restriction=True)\n",
    "        score = {}\n",
    "        ntypes = walks.keys()\n",
    "        for ntype in ntypes:\n",
    "            score[ntype] = []\n",
    "            for w in walks[ntype]:\n",
    "                node = w[0]\n",
    "                distinct_node_cnt = len(set(w))\n",
    "                if distinct_node_cnt > 0:\n",
    "                    s = distinct_node_cnt/len(w)\n",
    "                else:\n",
    "                    s = 0                \n",
    "                score[ntype].append([node, s])\n",
    "        return score\n",
    "\n",
    "    def get_embedding(self, H):\n",
    "        \"\"\"\n",
    "        Return the embeddings.\n",
    "        :param H: The output dimension of embeddings. After projection, every node_id becomes an H-dim array.\n",
    "        :return: Tensors in the shape of : [num of nodes, walk length, H]0\n",
    "        \"\"\"\n",
    "        # create input tensor\n",
    "        input_walks = []\n",
    "        for _, k in enumerate(self.walks):\n",
    "            input_walks.extend([w for w in self.walks[k]])\n",
    "        input_tensor = torch.tensor(input_walks)\n",
    "\n",
    "        # train the embedding\n",
    "        embedding_layer = nn.Embedding(num_embeddings=self.num_of_nodes, embedding_dim=H) # need unique keys for this method\n",
    "        _embedding = embedding_layer(input_tensor)\n",
    "\n",
    "        # sort into different ntypes\n",
    "        embedding_walk = {}\n",
    "        start = 0\n",
    "        for pair in self.num_of_nodes_ntype:\n",
    "            ntype = pair[0]\n",
    "            n = pair[1]\n",
    "            embedding_walk[ntype] = _embedding[start:(start + n)]\n",
    "            start += n\n",
    "        return embedding_walk\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "Ln5wSmg_qU1r",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ln5wSmg_qU1r",
    "outputId": "8ae9d002-912d-4524-b3a4-910faa8824d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'customer': tensor([[[0.8578],\n",
      "         [0.8578],\n",
      "         [0.8578],\n",
      "         [0.8578]]], grad_fn=<SliceBackward>), 'product': tensor([[[1.1810],\n",
      "         [0.8578],\n",
      "         [0.0417],\n",
      "         [0.8578]]], grad_fn=<SliceBackward>)}\n"
     ]
    }
   ],
   "source": [
    "### driver ###\n",
    "deepwalk = DeepWalk(g=ecommerce_hetero_graph, \n",
    "                    node_edge_pairs=[['customer', 'orders', 'rev-orders'],['product', 'rev-orders', 'orders']],\n",
    "                    walk_length=3, \n",
    "                    walks_per_node=1)\n",
    "deep_walk = deepwalk.get_feature_walk()\n",
    "same_type_walk = deepwalk.get_feature_walk(node_type_restriction=True)\n",
    "diversity_score = deepwalk.get_feature_diversity_score()\n",
    "embedding_walk = deepwalk.get_embedding(H=1)\n",
    "\n",
    "# print(deep_walk)\n",
    "# print('---------------')\n",
    "# print(same_type_walk)\n",
    "# print('---------------')\n",
    "# print(diversity_score)\n",
    "# print('---------------')\n",
    "print(embedding_walk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "44d81b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in deep_walk:\n",
    "    deep_walk[key] = torch.tensor(deep_walk[key]).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5aed18cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     0,     0,     0],\n",
       "        [    1,     0,     6,     0],\n",
       "        [    2,     0,     6,     0],\n",
       "        ...,\n",
       "        [96513, 32168, 96513, 32168],\n",
       "        [96514, 32169, 96514, 32169],\n",
       "        [96515, 32170, 96515, 32170]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_walk['customer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "31aed7bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'customer': tensor([[[0.8578],\n",
       "          [0.8578],\n",
       "          [0.8578],\n",
       "          [0.8578]]], grad_fn=<SliceBackward>),\n",
       " 'product': tensor([[[1.1810],\n",
       "          [0.8578],\n",
       "          [0.0417],\n",
       "          [0.8578]]], grad_fn=<SliceBackward>)}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_walk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OAfGsYqJnNl4",
   "metadata": {
    "id": "OAfGsYqJnNl4"
   },
   "source": [
    "### In-degree, Out-degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ozrKu_yxnSpm",
   "metadata": {
    "id": "ozrKu_yxnSpm"
   },
   "outputs": [],
   "source": [
    "def indegree_feature(graph):\n",
    "    output = {}\n",
    "    for s_ntype in graph.ntypes:\n",
    "        for d_ntype in graph.ntypes:\n",
    "            if s_ntype!=d_ntype:\n",
    "                print(\"Calculating indegree for source ntype: \", s_ntype, \"and dest ntype: \", d_ntype)\n",
    "                indegree_sum = None\n",
    "                for etype in graph.etypes:\n",
    "                    try:\n",
    "                        indegree = graph.in_degrees(etype=(s_ntype, etype, d_ntype))\n",
    "                        if indegree_sum:\n",
    "                            indegree_sum += indegree\n",
    "                        else:\n",
    "                            indegree_sum = indegree\n",
    "                    except:\n",
    "                        print(f'no edge type {etype} between source {s_ntype} and dest {d_ntype}')\n",
    "                        \n",
    "                indegree_tensor = torch.FloatTensor([[val] for val in indegree_sum])\n",
    "                output[d_ntype] = indegree_tensor\n",
    "    return output\n",
    "\n",
    "def outdegree_feature(graph):\n",
    "    output = {}\n",
    "    for s_ntype in graph.ntypes:\n",
    "        for d_ntype in graph.ntypes:\n",
    "            if s_ntype!=d_ntype:\n",
    "                print(\"Calculating outdegree for source ntype: \", s_ntype, \"and dest ntype: \", d_ntype)\n",
    "                outdegree_sum = None\n",
    "                for etype in graph.etypes:\n",
    "                    try:\n",
    "                        outdegree = graph.out_degrees(etype=(d_ntype, etype, s_ntype))\n",
    "                        if outdegree_sum:\n",
    "                            outdegree_sum += outdegree\n",
    "                        else:\n",
    "                            outdegree_sum = outdegree\n",
    "                    except:\n",
    "                        print(f'no edge type {etype} between source {d_ntype} and dest {s_ntype}')\n",
    "                        \n",
    "                outdegree_tensor = torch.FloatTensor([[val] for val in outdegree_sum])\n",
    "                output[d_ntype] = outdegree_tensor\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "zZUY8wBdnYvI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zZUY8wBdnYvI",
    "outputId": "01cffa22-8c22-4ebb-b75d-ee86e2a3a359"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating indegree for source ntype:  customer and dest ntype:  product\n",
      "no edge type rev-orders between source customer and dest product\n",
      "Calculating indegree for source ntype:  product and dest ntype:  customer\n",
      "no edge type orders between source product and dest customer\n",
      "Calculating outdegree for source ntype:  customer and dest ntype:  product\n",
      "no edge type orders between source product and dest customer\n",
      "Calculating outdegree for source ntype:  product and dest ntype:  customer\n",
      "no edge type rev-orders between source customer and dest product\n",
      "{'product': tensor([[11.],\n",
      "        [ 3.],\n",
      "        [10.],\n",
      "        ...,\n",
      "        [ 1.],\n",
      "        [ 1.],\n",
      "        [ 1.]]), 'customer': tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])} {'product': tensor([[11.],\n",
      "        [ 3.],\n",
      "        [10.],\n",
      "        ...,\n",
      "        [ 1.],\n",
      "        [ 1.],\n",
      "        [ 1.]]), 'customer': tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])}\n"
     ]
    }
   ],
   "source": [
    "### driver ###\n",
    "indegree = indegree_feature(ecommerce_hetero_graph)\n",
    "outdegree = outdegree_feature(ecommerce_hetero_graph)\n",
    "\n",
    "print(indegree, outdegree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8wU9U0E5X-bw",
   "metadata": {
    "id": "8wU9U0E5X-bw"
   },
   "source": [
    "### PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0xFo-j05YBwn",
   "metadata": {
    "id": "0xFo-j05YBwn"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    PageRank Helper Function\n",
    "\"\"\"\n",
    "def pagerank_reduce_func(nodes, DAMP=.85):\n",
    "    msgs = torch.sum(nodes.mailbox['pagerank_pv'], dim=1)\n",
    "    N = nodes.batch_size()\n",
    "\n",
    "    pv = (1 - DAMP) / N + DAMP * msgs\n",
    "    return {'pagerank_pv' : pv}\n",
    "\n",
    "def pagerank_message_func(edges):\n",
    "    return {'pagerank_pv' : edges.src['pagerank_pv'] / edges.src['pagerank_deg']}\n",
    "\n",
    "\"\"\"\n",
    "PageRank\n",
    "\n",
    "Implements Pagerank features in bypartite GNN\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "g : DGL Heterograph \n",
    "    The Graph should contain two node types only.\n",
    "user_label : string, optional\n",
    "    Name of the user node\n",
    "product_label: string, optional\n",
    "    Name of the product node\n",
    "edge_label: string, optional\n",
    "    Name of the user to product edge type\n",
    "rev_edge_label: string, optional\n",
    "    Name of the product to user edge type\n",
    "DAMP: float, optional\n",
    "    Damp or decay factor. This corresponds to the probability of connections sinking at any giving point (nodes with no outgoing edges). \n",
    "    It prevents the sinked nodes from \"absorbing\" the PageRanks of those pages connected to the sinks. \n",
    "reverse: bool, optional\n",
    "    Whether or not the PageRank algorithm should run on the reverse orientation (products to users)\n",
    "\n",
    "Returns\n",
    "    \n",
    "-------\n",
    "DGL Heterograph \n",
    "    The Graph with pagerank features included in its nodes (\"pagerank_pv\").\n",
    "\"\"\"\n",
    "def pagerank(g, user_label = 'user', product_label = 'product', edge_label = 'purchase', rev_edge_label = 'review', DAMP = 0.85, reverse = False):\n",
    "   \n",
    "    N = g.number_of_nodes()\n",
    "    N_user = g.num_src_nodes(user_label)\n",
    "    N_product = g.num_src_nodes(product_label)\n",
    "    \n",
    "    g.nodes[user_label].data['pagerank_pv'] = torch.ones(N_user) / N\n",
    "    g.nodes[product_label].data['pagerank_pv'] = torch.ones(N_product) / N\n",
    "    g.nodes[user_label].data['pagerank_deg'] = g.out_degrees(g.nodes(user_label), etype=edge_label).float()\n",
    "    g.nodes[product_label].data['pagerank_deg'] = g.out_degrees(g.nodes(product_label), etype=rev_edge_label).float()\n",
    "\n",
    "    g.multi_update_all({edge_label: (pagerank_message_func, pagerank_reduce_func)},\"sum\")\n",
    "    \n",
    "    if(reverse):\n",
    "        g.multi_update_all({rev_edge_label: (pagerank_message_func, pagerank_reduce_func)},\"sum\")\n",
    " \n",
    "    dict1 = {}\n",
    "    dict1[user_label] = torch.unsqueeze(g.nodes[user_label].data['pagerank_pv'], 1) \n",
    "    dict1[product_label] = torch.unsqueeze(g.nodes[product_label].data['pagerank_pv'], 1)\n",
    "    return dict1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "X5XJ5lt5ZbzC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X5XJ5lt5ZbzC",
    "outputId": "b52dcb79-05a2-4505-a4e2-84ad01e87f20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'customer': tensor([[7.7708e-06],\n",
      "        [7.7708e-06],\n",
      "        [7.7708e-06],\n",
      "        ...,\n",
      "        [7.7708e-06],\n",
      "        [7.7708e-06],\n",
      "        [7.7708e-06]]), 'product': tensor([[7.8785e-04],\n",
      "        [6.8931e-05],\n",
      "        [6.2649e-04],\n",
      "        ...,\n",
      "        [1.5464e-05],\n",
      "        [1.5464e-05],\n",
      "        [1.5464e-05]])}\n"
     ]
    }
   ],
   "source": [
    "### driver ###\n",
    "pagerank = pagerank(ecommerce_hetero_graph, \n",
    "             user_label = 'customer', \n",
    "             product_label = 'product', \n",
    "             edge_label = 'orders', \n",
    "             rev_edge_label = 'rev-orders',\n",
    "             reverse = False)\n",
    "\n",
    "print(pagerank)\n",
    "# print(movie_hetero_graph_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dcc11690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32171, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pagerank['product'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Z1HvELx8Wllm",
   "metadata": {
    "id": "Z1HvELx8Wllm"
   },
   "source": [
    "### Concatenate feature tensors and add to graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1Kb9ltx2TXUg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Kb9ltx2TXUg",
    "outputId": "9a9e7592-f00b-4520-f424-fd9174b6dd8a"
   },
   "outputs": [],
   "source": [
    "def concat_feature_tensors(node_types, **kwargs):\n",
    "    \"\"\"\n",
    "    Take in multiple feature tensors, check if its a valid tensor size, and concatenate them.\n",
    "    Output: Dict with different ntype as keys, tensors as value.\n",
    "    \"\"\"\n",
    "    out_feature_tensors = {}\n",
    "    for ntype in node_types:\n",
    "        for key, value in kwargs.items():\n",
    "            tensors = value[ntype]        \n",
    "    \n",
    "            # sanity check: tensor size\n",
    "            if tensors.dim() > 3:\n",
    "                return \"Error dimension in feature:{}\".format(key)\n",
    "            if tensors.dim() == 3:\n",
    "                value[ntype] = tensors.flatten(1, 2)\n",
    "            # print(key, ntype, value[ntype])\n",
    "        \n",
    "        out_feature_tensors[ntype] = torch.cat(tuple([v[ntype] for k, v in kwargs.items()]), \n",
    "                                               dim=-1)\n",
    "    return out_feature_tensors\n",
    "\n",
    "def add_features_to_graph(g: dgl.DGLGraph, feature_tensor_to_add: torch.tensor):\n",
    "    \"\"\"\n",
    "    Append feature tensors to the nodes in graph.\n",
    "    \"\"\"\n",
    "    # if there's exsiting features in the graph\n",
    "    exist_features = {}\n",
    "    for ntype in g.ntypes:\n",
    "        if (\"features\" in g.nodes[ntype].data.keys()) and (g.nodes[ntype].data[\"features\"] is not None):\n",
    "            exist_features[ntype] = g.nodes[ntype].data[\"features\"]\n",
    "    \n",
    "    feature_tensor_to_add = concat_feature_tensors(node_types=g.ntypes,\n",
    "#                                                     exist_feature=exist_features, \n",
    "                                                    feature_tensor_to_add=feature_tensor_to_add)\n",
    "    # append features to the graph\n",
    "    for ntype in g.ntypes:\n",
    "        g.nodes[ntype].data[\"features\"] = feature_tensor_to_add[ntype]    \n",
    "    return g\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bKhHHK2MVuww",
   "metadata": {
    "id": "bKhHHK2MVuww"
   },
   "outputs": [],
   "source": [
    "### driver ###\n",
    "structural_feature_tensors = concat_feature_tensors(node_types=[\"customer\",\"product\"], \n",
    "                                          in_degree=indegree,\n",
    "                                          out_degree=outdegree,\n",
    "                                          pagerank=pagerank,\n",
    "                                          walk_embeddings=deep_walk,\n",
    "                                          )\n",
    "\n",
    "# movie_hetero_graph_clean = add_features_to_graph(movie_hetero_graph_clean, structural_feature_tensors)\n",
    "\n",
    "# print(movie_hetero_graph_clean.nodes[\"user\"].data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cc042f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecommerce_hetero_graph_clean = add_features_to_graph(ecommerce_hetero_graph, structural_feature_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0ec1d031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 1.0000e+00, 7.7708e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecommerce_hetero_graph_clean.nodes[\"customer\"].data['features'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e10ebe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "88625f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indegree['customer'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b2ca862f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([96516, 1])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outdegree['customer'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "967e9ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.7708e-06])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pagerank['customer'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "68cf2918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.7708e-06])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pagerank['customer'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bcf35f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
